{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3 MinHash1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "MnkJKQKm-9b1",
        "colab_type": "code",
        "outputId": "2eee4327-63fe-4be1-d9c2-fef0359d3351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: py4j==0.10.7 in /usr/local/lib/python3.6/dist-packages (from pyspark) (0.10.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fJPs8hrSlEtX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext,SparkSession\n",
        "from pyspark.ml.feature import CountVectorizer,MinHashLSH\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import *\n",
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql.functions import udf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H1za-XiO6sFn",
        "colab_type": "code",
        "outputId": "2bc4561b-5b15-47a0-c8ed-8b488465cdef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip cook.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cook.zip\n",
            "replace cook/amem.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nlIHU6KplEte",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Q3 MinHash\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "sqlContext = SQLContext(sc)\n",
        "data = sc.wholeTextFiles('cook')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pMkm4awmlEtm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_final = data.map(lambda x: Row(Filename=x[0],Data=x[1].strip()))\n",
        "schema = \"Filename Data\"\n",
        "fields = [StructField(field_name, StringType(), True) for field_name in schema.split()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YJd1Ixl6lEtq",
        "colab_type": "code",
        "outputId": "a2891db1-8470-401a-c73a-8359105720dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "cell_type": "code",
      "source": [
        "schema_final = StructType(fields)\n",
        "df1 = spark.createDataFrame(data_final, schema_final)\n",
        "df1.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|            Filename|                Data|\n",
            "+--------------------+--------------------+\n",
            "|file:/content/coo...|The American Woma...|\n",
            "|file:/content/coo...|THE \r\n",
            "\r\n",
            "IDEAL BAR...|\n",
            "|file:/content/coo...|Manual For Army C...|\n",
            "|file:/content/coo...|\"Aunt Babette's\" ...|\n",
            "|file:/content/coo...|The American Matr...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1NFiIkEDAyfC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Function to calculate shingle**"
      ]
    },
    {
      "metadata": {
        "id": "hKsX_mKvlEtw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "def get_shingles(text):\n",
        "\n",
        "    text = text.replace('\\r', '')\n",
        "    text = text.replace('\\n', '')\n",
        "    text = re.sub('[^a-zA-Z0-9]+', ' ', text)\n",
        "    text = text.lstrip().split(\" \")  \n",
        "    shingles = [text[i:i+3] for i in range(len(text)-3+1)]\n",
        "    \n",
        "    return shingles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VXbutAC3lEtz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text_shingle = lambda y: get_shingles(y)\n",
        "shingle_final = udf(text_shingle,ArrayType(StringType()))\n",
        "\n",
        "df_shingle = df1.withColumn(\"shingles\", shingle_final(df1.Data))\n",
        "df_shingle = df_shingle.drop(\"Data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_QGHlg0lEuB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "countVectorizer = CountVectorizer(inputCol=\"shingles\", outputCol=\"features\", vocabSize = 100000, minDF=2)\n",
        "model_cv = countVectorizer.fit(df_shingle)\n",
        "result = model_cv.transform(df_shingle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JAuQVKbUlEuE",
        "colab_type": "code",
        "outputId": "c8c8dcd8-4593-41fa-bed9-9907ab1491b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "minHash = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", seed=12345)\n",
        "model_minHash = minHash.fit(result)\n",
        "result_minHash = model_minHash.transform(result)\n",
        "result_minHash.show()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+--------------------+----------------+\n",
            "|            Filename|            shingles|            features|          hashes|\n",
            "+--------------------+--------------------+--------------------+----------------+\n",
            "|file:/content/coo...|[[The, American, ...|(9166,[0,2,3,5,6,...|    [[294644.0]]|\n",
            "|file:/content/coo...|[[THE, IDEAL, BAR...|(9166,[6,14,15,17...|    [[482803.0]]|\n",
            "|file:/content/coo...|[[Manual, For, Ar...|(9166,[0,1,2,3,4,...|    [[294644.0]]|\n",
            "|file:/content/coo...|[[Aunt, Babette, ...|(9166,[0,1,2,3,4,...|    [[294644.0]]|\n",
            "|file:/content/coo...|[[The, American, ...|(9166,[18,700,390...|[[9.46173052E8]]|\n",
            "+--------------------+--------------------+--------------------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HcLlsxrtlEuL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "resultDF = result_minHash.drop(\"shingles\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LyA5BT147u6F",
        "colab_type": "code",
        "outputId": "494a780e-282e-474f-85db-5b6ff40417ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "resultDF.show(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+----------------+\n",
            "|            Filename|            features|          hashes|\n",
            "+--------------------+--------------------+----------------+\n",
            "|file:/content/coo...|(9166,[0,2,3,5,6,...|    [[294644.0]]|\n",
            "|file:/content/coo...|(9166,[6,14,15,17...|    [[482803.0]]|\n",
            "|file:/content/coo...|(9166,[0,1,2,3,4,...|    [[294644.0]]|\n",
            "|file:/content/coo...|(9166,[0,1,2,3,4,...|    [[294644.0]]|\n",
            "|file:/content/coo...|(9166,[18,700,390...|[[9.46173052E8]]|\n",
            "+--------------------+--------------------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MO3kAXXplEuO",
        "colab_type": "code",
        "outputId": "0bd6ecc7-7bc4-4c0b-81ff-7eb40aaa2e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "relation = model_minHash.approxSimilarityJoin(resultDF, resultDF, 0.5).filter(\"distCol != 0.0\")\n",
        "relation.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-------------------+\n",
            "|            datasetA|            datasetB|            distCol|\n",
            "+--------------------+--------------------+-------------------+\n",
            "|[file:/content/co...|[file:/content/co...|0.40930079155672827|\n",
            "|[file:/content/co...|[file:/content/co...|0.40930079155672827|\n",
            "+--------------------+--------------------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8IdVgz51-qgt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Reference: https://mattilyra.github.io/2017/05/23/document-deduplication-with-lsh.html"
      ]
    }
  ]
}